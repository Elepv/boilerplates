net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1 # 使二层的网桥在转发包时也会被iptables的FORWARD规则所过滤
net.bridge.bridge-nf-call-ip6tables = 1

# swappiness=0的时候表示最大限度使用物理内存，然后才是 swap空间
vm.swappiness=0

# RHEL7.4引入用于控制内核的行为。使用容器（docker或其它容器）必需启用，默认值0
# 参看：https://bugzilla.redhat.com/show_bug.cgi?id=1441737
fs.may_detach_mounts = 1

# 0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。
# 1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。
# 2， 表示内核允许分配超过所有物理内存和交换空间总和的内存
vm.overcommit_memory=0

# 默认为0开启为1时表示关闭此功能等于0时，表示当内存耗尽时，内核会触发OOM killer杀掉最耗内存的进程。当OOMKiller被启动时，通过观察进程自动计算得出各当前进程的得分 /proc/<PID>/oom_score,分值越高越容易被kill掉。
# 参看：https://www.cnblogs.com/zengkefu/p/5683606.html
vm.panic_on_oom=0

fs.inotify.max_user_watches=89100

# 设置 系统所有进程一共可以打开的文件数量
fs.file-max=52706963

# nr_open是单个进程可分配的最大文件数，ulimit -n 的最大值
# 参看：https://blog.csdn.net/weixin_34266504/article/details/92383575
fs.nr_open=52706963

# # 最大跟踪连接数，默认 nf_conntrack_buckets * 4
# 参看：https://www.cnblogs.com/xiangsikai/p/9525287.html
# sysctl net.netfilter.nf_conntrack_count
net.netfilter.nf_conntrack_max=2310720

# tcp_keepalive_time 值控制 TCP/IP 尝试验证空闲连接是否完好的频率。 如果这段时间内没有活动，则会发送保持活动信号。如果网络工作正常，而且接收方是活动的，它就会响应。 如果需要对丢失接收方敏感，换句话说，需要更快地发现丢失了接收方，请考虑减小这个值。 如果长期不活动的空闲连接出现次数较多，而丢失接收方的情况出现较少，您可能会要提高该值以减少开销。缺省情况下，如果空闲连接7200秒（2小时）内没有活动，Linux就发送保持活动的消息。通常，1800 秒是首选值，从而一半的已关闭连接会在 30 分钟内被检测到。
# 参考：http://blog.chinaunix.net/uid-23849526-id-269736.html
net.ipv4.tcp_keepalive_time = 600
# 共发生3次侦探包
net.ipv4.tcp_keepalive_probes = 3
# 每隔15秒就会发送侦探包
net.ipv4.tcp_keepalive_intvl =15

# 因为前些天遇到大量TIME_WAIT导致端口耗尽服务异常的情况，让我注意到这个参数。先说它的作用：在 TIME_WAIT 数量等于 tcp_max_tw_buckets 时，不会有新的 TIME_WAIT 产生。
# 参看：https://www.jianshu.com/p/b7e991be0909
# 设置为很小的值(默认是18000). 当TIME_WAIT连接数量达到给定的值时，所有的TIME_WAIT连接会被立刻清除，并打印警告信息。但这种粗暴的清理掉所有的连接，意味着有些连接并没有成功等待2MSL，就会造成通讯异常
# 参考：http://blog.itpub.net/31559359/viewspace-2284113/
net.ipv4.tcp_max_tw_buckets = 36000

# 将处于TIME_WAIT状态的socket用于新的TCP连接，影响连出的连接。
# 参考：http://blog.itpub.net/31559359/viewspace-2284113/
net.ipv4.tcp_tw_reuse = 1

#表示系统中最多有多少TCP套接字不被关联到任何一个用户文件句柄上。如果超过这里设置的数字，连接就会复位并输出警告信息。这个限制仅仅是为了防止简单的DoS攻击。此值不能太小。
net.ipv4.tcp_max_orphans = 327680

# 主要是针对孤立的socket(也就是已经从进程上下文中删除了，可是还有一些清理工作没有完成).对于这种socket，我们重试的最大的次数就是它
# 参看：https://blog.51cto.com/smileyouth/1753394
net.ipv4.tcp_orphan_retries = 3

# 开启SYN洪水攻击保护
# 参看：https://blog.51cto.com/smileyouth/1753394
net.ipv4.tcp_syncookies = 1

# 记录的那些尚未收到客户端确认信息的连接请求的最大值。
# https://blog.51cto.com/smileyouth/1753394
net.ipv4.tcp_max_syn_backlog = 16384

# net.ipv4.ip_conntrack_max = 65536
# net.ipv4.tcp_max_syn_backlog = 16384

# 在docker和nginx反向代理的环境中，必需要设置下面这条，否则业务繁忙时会无法正常连接nat后面的端口或反向代理后面的服务器，因为nat端口或反向代理端口会被复用
# http://www.openskill.cn/article/443
# 参看：https://zhuanlan.zhihu.com/p/145939529
net.ipv4.tcp_timestamps = 0

# net.core.somaxconn是Linux中的一个内核(kernel)参数，表示socket监听(listen)的backlog上限。什么是backlog？backlog就是socket的监听队列，当一个请求(request)尚未被处理或者建立时，它就会进入backlog。而socket server可以一次性处理backlog中的所有请求，处理后的请求不再位于监听队列中。当Server处理请求较慢时，导致监听队列被填满后，新来的请求就会被拒绝。
# 参考：https://blog.csdn.net/qq_31851107/article/details/103497779
net.core.somaxconn = 16384